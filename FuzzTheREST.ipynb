{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from gym) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from gym) (3.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from matplotlib) (4.48.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: requests in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from requests) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (6.0.1)\n",
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from nltk>=3.1->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from nltk>=3.1->textblob) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from nltk>=3.1->textblob) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from nltk>=3.1->textblob) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\tiago\\anaconda3\\envs\\fuzztherest_env\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "!pip install gym\n",
    "!pip install matplotlib\n",
    "!pip install numpy\n",
    "!pip install requests\n",
    "!pip install PyYAML\n",
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, requests, random, sys, struct, string\n",
    "import numpy as np\n",
    "import yaml\n",
    "import json, copy\n",
    "from requests.exceptions import ChunkedEncodingError\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_body(object_data, existing_objects: dict):\n",
    "    \"\"\"Converts components of the OpenAPI specifications to JSON objects.\n",
    "\n",
    "    Args:\n",
    "        object_data (yaml): component to be built.\n",
    "        existing_objects (dict): components already built that may be referenced in other components.\n",
    "\n",
    "    Returns:\n",
    "        JSON: The component in a JSON format. \n",
    "    \"\"\"\n",
    "    json_body = {}\n",
    "    property_dict = {}\n",
    "\n",
    "    if 'properties' in object_data:  # If its an object of the domain. Otherwise it would be in the requestBodies.\n",
    "        properties = object_data['properties']\n",
    "\n",
    "        for prop_name, prop_data in properties.items():\n",
    "            if 'type' in prop_data:\n",
    "                prop_type = prop_data['type']\n",
    "                if prop_type == 'array': # Arrays will have items: and then either type or $ref inside\n",
    "                    if 'type' in prop_data['items']:\n",
    "                        array_type = prop_data['items']['type']\n",
    "                        property_dict[prop_name] = [array_type]\n",
    "                    elif '$ref' in prop_data['items']:\n",
    "                        array_type = prop_data['items']['$ref']\n",
    "                        prop_ref = array_type.split('/')[-1]\n",
    "                        obj_type = existing_objects.get(prop_ref)\n",
    "                        if(obj_type is None):\n",
    "                            raise ValueError(\"unable to find existing object\")\n",
    "                        property_dict[prop_name] = [obj_type]\n",
    "                else:\n",
    "                    property_dict[prop_name] = prop_type\n",
    "            elif '$ref' in prop_data:\n",
    "                prop_ref = prop_data['$ref'].split('/')[-1]\n",
    "                obj_type = existing_objects.get(prop_ref)\n",
    "                if(obj_type is None):\n",
    "                    raise ValueError(\"unable to find existing object\")\n",
    "                property_dict[prop_name] = obj_type\n",
    "        return property_dict\n",
    "    else:\n",
    "        prop_data_content = object_data['content']\n",
    "        if 'application/json' in prop_data_content:\n",
    "            return create_json_body(prop_data_content['application/json']['schema'], existing_objects)\n",
    "        elif 'multipart/form-data' in prop_data_content:\n",
    "            return create_json_body(prop_data_content['multipart/form-data']['schema'], existing_objects)\n",
    "\n",
    "\n",
    "        # if '$ref' in prop_data:\n",
    "        #     return existing_objects.get(prop_data['$ref'].split('/')[-1])\n",
    "        # elif prop_data['type'] == \"array\":\n",
    "        #     return [existing_objects.get(prop_data['items']['$ref'].split('/')[-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_body_values(schema, old_sample, contains_previous, mutation_methods, schema_name, store_id):\n",
    "    if schema is not None:\n",
    "        sample = copy.deepcopy(schema)\n",
    "        if contains_previous:\n",
    "            sample = fill_previous_body(sample, old_sample)\n",
    "\n",
    "        for item in sample.items():\n",
    "            if item[1] is None:\n",
    "                print(\"THIS ITEM IS NONEE!!!!\")\n",
    "                print(sample)\n",
    "            if type(item[1]) is list:\n",
    "                list_size = random.randint(0,100)\n",
    "                values = []\n",
    "\n",
    "                if list_size <= len(item[1]):\n",
    "                    values = item[1][0:list_size]\n",
    "                else:\n",
    "                    values = [schema[item[0]][0]] * list_size\n",
    "                    values[0:len(item[1])] = item[1]\n",
    "                \n",
    "                for i in range(list_size):\n",
    "                    if type(values[i]) is dict:\n",
    "                        if type(schema[item[0]]) is list:\n",
    "                            values[i] = fill_body_values(schema[item[0]][0], values[i], contains_previous, mutation_methods, item[0], store_id)\n",
    "                        else:\n",
    "                            values[i] = fill_body_values(schema[item[0]], values[i], contains_previous, mutation_methods, item[0], store_id)\n",
    "\n",
    "                    else:\n",
    "                        if type(values[i]) is str and values[i] in {\"integer\", \"double\", \"float\", \"string\", \"boolean\"}:\n",
    "                            val = get_mutated_value(None, values[i], None, Word(schema_name.capitalize()).singularize())\n",
    "                            if val is None:\n",
    "                                print(\"Val is None!\")\n",
    "                            values[i] = val\n",
    "                        else:\n",
    "                            val = get_mutated_value(values[i], None, mutation_methods[type(values[i])], Word(schema_name.capitalize()).singularize())\n",
    "                            if val is None:\n",
    "                                print(\"Val is None!\")\n",
    "                            values[i] = val\n",
    "\n",
    "                sample[item[0]] = values\n",
    "\n",
    "                if item[0] == 'id' and store_id:\n",
    "                    for value in values:\n",
    "                        if value not in ids[Word(schema_name.capitalize()).singularize()]:\n",
    "                            ids[Word(schema_name.capitalize()).singularize()].append(value)\n",
    "\n",
    "            else:\n",
    "                if type(item[1]) is dict:\n",
    "                        sample[item[0]] = fill_body_values(schema[item[0]], item[1], contains_previous, mutation_methods,item[0], store_id)\n",
    "                else:\n",
    "                    if type(item[1]) is str and item[1] in {\"integer\", \"double\", \"float\", \"string\", \"boolean\"}:\n",
    "                        val = get_mutated_value(None, item[1], None, Word(schema_name.capitalize()).singularize())\n",
    "                        if val is None:\n",
    "                                print(\"Val is None!\")\n",
    "                        sample[item[0]] = val\n",
    "                    else:\n",
    "                        val = get_mutated_value(item[1], None,  mutation_methods[type(item[1])], Word(schema_name.capitalize()).singularize())\n",
    "                        if val is None:\n",
    "                            print(\"Val is None!\")\n",
    "                        sample[item[0]] = val\n",
    "\n",
    "                    if item[0] == 'id' and store_id:\n",
    "                        if sample[item[0]] not in ids[Word(schema_name.capitalize()).singularize()]:\n",
    "                            ids[Word(schema_name.capitalize()).singularize()].append(sample[item[0]])\n",
    "\n",
    "        return sample\n",
    "\n",
    "def fill_previous_body(schema, old_sample):\n",
    "    sample = copy.deepcopy(schema)\n",
    "    for item in old_sample.items():\n",
    "        if type(item[1]) is list:\n",
    "            if len(item[1]) > 0:\n",
    "                if item[1][0] is dict:\n",
    "                    #TODO Implement to when it is a dict inside a list\n",
    "                    raise ValueError(\"Unsuported dict inside list verification\")\n",
    "                else:\n",
    "                    sample[item[0]] = item[1]\n",
    "        else:\n",
    "            if type(item[1]) is dict:\n",
    "                sample[item[0]] = fill_previous_body(sample[item[0]], item[1])\n",
    "            else:\n",
    "                sample[item[0]] = item[1]\n",
    "    \n",
    "\n",
    "    return sample\n",
    "\n",
    "\n",
    "def fill_parameter_values(input_parameters, contains_previous, mutation_methods):\n",
    "    for parameter in input_parameters:\n",
    "        parameter_name = parameter['name'].lower()\n",
    "        if 'id' in parameter_name:\n",
    "            parameter_name = parameter_name.replace('id', '').capitalize()\n",
    "        if type(parameter['schema']) is list:\n",
    "            list_size = random.randint(0,100)\n",
    "            values = []\n",
    "            if contains_previous:\n",
    "                if list_size <= len(parameter['sample']):\n",
    "                    values = parameter['sample'][0:list_size]\n",
    "                else:\n",
    "                    values = [random_generation(type(parameter['sample'][0]))] * list_size\n",
    "                    values[0:len(parameter['sample'])] = parameter['sample']\n",
    "                \n",
    "                for i in range(list_size):\n",
    "                    values[i] = get_mutated_value(values[i], None, mutation_methods[type(values[i])], parameter_name)\n",
    "                \n",
    "            else:\n",
    "                for i in range(list_size):\n",
    "                    values.append(get_mutated_value(None, parameter['schema'][0], None, parameter_name))\n",
    "\n",
    "\n",
    "            parameter[\"sample\"] = values\n",
    "\n",
    "        else:\n",
    "            if contains_previous:\n",
    "                parameter['sample'] = get_mutated_value(parameter['sample'], parameter['schema'], mutation_methods[type(parameter['sample'])], parameter_name)\n",
    "            else:\n",
    "                parameter['sample'] = get_mutated_value(None, parameter['schema'], None, parameter_name)\n",
    "\n",
    "    return input_parameters\n",
    "\n",
    "\n",
    "def fill_values(function, contains_previous_values, mutation_methods, store_id):\n",
    "    function['input_parameters'] = fill_parameter_values(function['input_parameters'], contains_previous_values, mutation_methods)\n",
    "\n",
    "    if type(function['input_body']['schema']) is list:\n",
    "        list_size = random.randint(0,100)\n",
    "        list_schema = function['input_body']['schema'][0]\n",
    "        items = []\n",
    "        for i in range(list_size):\n",
    "            items.append(fill_body_values(list_schema, function['input_body']['sample'], contains_previous_values, mutation_methods, function['input_body']['schema_name'], store_id))\n",
    "\n",
    "        function['input_body']['sample'] = items\n",
    "    else:\n",
    "        function['input_body']['sample'] = fill_body_values(function['input_body']['schema'], function['input_body']['sample'], contains_previous_values, mutation_methods, function['input_body']['schema_name'], store_id)\n",
    "\n",
    "    return function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bit Flips: Randomly flips individual bits in the input data.\n",
    "# Bit Flips: Randomly flips individual bits in the input data.\n",
    "def bit_flips(data):\n",
    "    if isinstance(data, str):\n",
    "        chars = list(data)\n",
    "        for i in range(len(chars)):\n",
    "            char_code = ord(chars[i])\n",
    "            flipped_code = char_code ^ random.getrandbits(16)\n",
    "            chars[i] = chr(flipped_code)\n",
    "        modified_data = ''.join(chars)\n",
    "        return modified_data\n",
    "    elif isinstance(data, bytes):\n",
    "        flipped_data = bytearray(data)\n",
    "        for i in range(len(flipped_data)):\n",
    "            flipped_data[i] = flipped_data[i] ^ random.getrandbits(8)\n",
    "        return bytes(flipped_data)\n",
    "    elif isinstance(data, bool):\n",
    "        flipped_data = not data\n",
    "        return flipped_data\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type for bit flips\")\n",
    "\n",
    "# Byte Shuffling: Shuffles the order of the bytes in the input data.\n",
    "def byte_shuffling(data):\n",
    "    if isinstance(data, str):\n",
    "        char_list = list(data)\n",
    "        random.shuffle(char_list)\n",
    "        shuffled_string = ''.join(char_list)\n",
    "        return shuffled_string\n",
    "    elif isinstance(data, bytes):\n",
    "        byte_list = list(data)\n",
    "        random.shuffle(byte_list)\n",
    "        return bytes(byte_list)\n",
    "    elif isinstance(data, bool):\n",
    "        return data\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type for byte shuffling\")\n",
    "\n",
    "# Byte Injection/Deletion: Adds or removes random bytes, causing structural changes to the input data.\n",
    "def byte_injection(data):\n",
    "    if isinstance(data, str):\n",
    "        code_points = list(data)\n",
    "        code_point_to_inject = chr(random.randint(0, 1114111))\n",
    "        index = random.randint(0, len(code_points))\n",
    "        code_points.insert(index, code_point_to_inject)\n",
    "        return ''.join(code_points)\n",
    "    elif isinstance(data, bytes):\n",
    "        mutated_data = bytearray(data)\n",
    "        byte_to_inject = random.randint(0, 255)\n",
    "        index = random.randint(0, len(mutated_data))\n",
    "        mutated_data.insert(index, byte_to_inject)\n",
    "        return bytes(mutated_data)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type for byte injection/deletion\")\n",
    "\n",
    "def byte_deletion(data):\n",
    "    if isinstance(data, str):\n",
    "        code_points = list(data)\n",
    "        if len(code_points) > 0:\n",
    "            index = random.randint(0, len(code_points) - 1)\n",
    "            del code_points[index]\n",
    "        return ''.join(code_points)\n",
    "    elif isinstance(data, bytes):\n",
    "        mutated_data = bytearray(data)\n",
    "        if len(mutated_data) > 0:\n",
    "            index = random.randint(0, len(mutated_data) - 1)\n",
    "            del mutated_data[index]\n",
    "        return bytes(mutated_data)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type for byte injection/deletion\")\n",
    "\n",
    "# Bytes Substitution: Randomly replaces bytes with others.\n",
    "def bytes_substitution(data):\n",
    "    if isinstance(data, str):\n",
    "        mutated_data = \"\"\n",
    "        for char in data:\n",
    "            if random.random() < 0.5:  # 50% probability for substitution\n",
    "                mutated_data += random.choice(string.printable)\n",
    "            else:\n",
    "                mutated_data += char\n",
    "        return mutated_data\n",
    "    elif isinstance(data, bytes):\n",
    "        mutated_data = bytearray(data)\n",
    "        for i in range(len(mutated_data)):\n",
    "            mutated_data[i] = random.randint(0, 255)\n",
    "        return bytes(mutated_data)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type for bytes substitution\")\n",
    "\n",
    "# Truncation: Shortens the input data by removing trailing bytes.\n",
    "def truncation(data):\n",
    "    if isinstance(data, str):\n",
    "        if len(data) > 1:\n",
    "            truncation_length = random.randint(0, len(data)-1)\n",
    "            return data[:-truncation_length]\n",
    "        else:\n",
    "            return data\n",
    "    elif isinstance(data, bytes):\n",
    "        if len(data) > 1:\n",
    "            truncation_length = random.randint(0, len(data)-1)\n",
    "            return data[:-truncation_length]\n",
    "        else:\n",
    "            return data\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type for truncation\")\n",
    "\n",
    "# Dictionary Fuzzy: only works for integers\n",
    "def dictionary_fuzzy(schema_name, ids):\n",
    "    if schema_name in ids.keys():\n",
    "        if len(ids[schema_name]) != 0:\n",
    "            value = random.choice(ids[schema_name])\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "def arithmetic_addition(data):\n",
    "    if isinstance(data, float):\n",
    "        return data + random.uniform(sys.float_info.min, sys.float_info.max)\n",
    "    elif isinstance(data, int):\n",
    "        new_value = data + random.randrange(-2147483648, 2147483647)\n",
    "        if new_value > 2147483647 or new_value < -2147483648:\n",
    "            return data\n",
    "        return new_value\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type for arithmetic operations\")\n",
    "\n",
    "def arithmetic_subtraction(data):\n",
    "    if isinstance(data, float):\n",
    "        return data - random.uniform(sys.float_info.min, sys.float_info.max)\n",
    "    elif isinstance(data, int):\n",
    "        new_value = data - random.randrange(-2147483648, 2147483647)\n",
    "        new_value = new_value & 0xFFFFFFFF  # 0xFFFFFFFF represents a 32-bit mask (all 1's)\n",
    "        # If the number exceeds the positive limit of 2147483647, convert to negative equivalent\n",
    "        if new_value > 2147483647 or new_value < -2147483648:\n",
    "            return data\n",
    "        return new_value\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type for arithmetic operations\")\n",
    "\n",
    "def arithmetic_multiplication(data):\n",
    "    if isinstance(data, float):\n",
    "        return data * random.uniform(sys.float_info.min, sys.float_info.max)\n",
    "    elif isinstance(data, int):\n",
    "        new_value = data * random.randrange(-2147483648, 2147483647)\n",
    "        new_value = new_value & 0xFFFFFFFF  # 0xFFFFFFFF represents a 32-bit mask (all 1's)\n",
    "        # If the number exceeds the positive limit of 2147483647, convert to negative equivalent\n",
    "        if new_value > 2147483647 or new_value < -2147483648:\n",
    "            return data\n",
    "        return new_value\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type for arithmetic operations\")\n",
    "\n",
    "def arithmetic_division(data):\n",
    "    if isinstance(data, float):\n",
    "        return data / random.uniform(sys.float_info.min, sys.float_info.max)\n",
    "    elif isinstance(data, int):\n",
    "        return data // random.randrange(-2147483648, 2147483647)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type for arithmetic operations\")\n",
    "\n",
    "# Random Generation: Randomly generates input of a certain type.\n",
    "def random_generation(data_type):\n",
    "    if data_type == str:\n",
    "        size = random.randint(0, 500)  # Random size between int min and int max\n",
    "        return ''.join(random.choice(string.printable) for _ in range(size))\n",
    "    elif data_type == int:\n",
    "        return random.randrange(-2147483648, 2147483647)  # Random integer between int min and int max\n",
    "    elif data_type == float:\n",
    "        return random.uniform(sys.float_info.min, sys.float_info.max)\n",
    "    elif data_type == bool:\n",
    "        return random.choice([True, False])\n",
    "    elif data_type == bytes:\n",
    "        size = random.randint(0, 500)  # Random size between 1 and 10\n",
    "        return bytes(random.randint(0, 255) for _ in range(size))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type for random generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to Convert to Binary\n",
    "def to_binary(data):\n",
    "    if isinstance(data, str):\n",
    "        binary_data = data.encode('utf-8')\n",
    "    elif isinstance(data, int):\n",
    "        binary_data = struct.pack(\"i\", data)\n",
    "    elif isinstance(data, float):\n",
    "        binary_data = struct.pack('d', data)\n",
    "    elif isinstance(data, bool):\n",
    "        binary_data = struct.pack('?', data)\n",
    "    elif isinstance(data, bytes):\n",
    "        binary_data = data\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type\")\n",
    "\n",
    "    return binary_data\n",
    "\n",
    "# Method to Convert From Binary to original data type.\n",
    "def from_binary(binary_data, data_type):\n",
    "    if data_type == str:\n",
    "        output_value = binary_data.decode('utf-8')\n",
    "    elif data_type == int:\n",
    "        output_value = struct.unpack(\"i\", binary_data)[0]\n",
    "    elif data_type == float:\n",
    "        output_value = struct.unpack('d', binary_data)[0]\n",
    "    elif data_type == bool:\n",
    "        output_value = struct.unpack('?', binary_data)[0]\n",
    "    elif data_type == bytes:\n",
    "        output_value = binary_data\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type\")\n",
    "\n",
    "    return output_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mutated_value(old_value, datatype, method, schema_name):\n",
    "        if old_value is None:\n",
    "            if datatype == 'integer':\n",
    "                return random_generation(int)\n",
    "            elif datatype == 'float' or datatype == 'double':\n",
    "                return random_generation(float)\n",
    "            elif datatype == 'boolean':\n",
    "                return random_generation(bool)\n",
    "            elif datatype == 'string':\n",
    "                return random_generation(str)\n",
    "            else:\n",
    "                random_generation(bytes)\n",
    "        else:\n",
    "            datatype = type(old_value)\n",
    "            if method is random_generation:\n",
    "                return random_generation(datatype)\n",
    "            elif method is dictionary_fuzzy:\n",
    "                new_value = dictionary_fuzzy(schema_name, ids)\n",
    "                if new_value is None:\n",
    "                    return old_value\n",
    "                else:\n",
    "                    return new_value\n",
    "            if datatype is int or datatype is float:\n",
    "                if method is arithmetic_division or method is arithmetic_addition or method is arithmetic_multiplication or method is arithmetic_subtraction:\n",
    "                    return method(old_value)\n",
    "                else:\n",
    "                    new_value_bin = to_binary(old_value)\n",
    "                    return from_binary(method(new_value_bin), datatype)\n",
    "            else:\n",
    "                return method(old_value)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.spaces import MultiDiscrete, Discrete\n",
    "import numpy as np\n",
    "\n",
    "class APIFuzzyTestingEnvironment(gym.Env):\n",
    "    def __init__(self, base_url, function, mutation_methods):\n",
    "        super(APIFuzzyTestingEnvironment, self).__init__()\n",
    "        self.function = function\n",
    "        self.base_url = base_url\n",
    "        self.response = None\n",
    "        self.mutation_methods = mutation_methods  # List of mutation methods.\n",
    "        self.action_space: MultiDiscrete = MultiDiscrete([len(methods) for methods in mutation_methods])\n",
    "        self.observation_space: Discrete = Discrete(5) # Possible HTTP error codes.\n",
    "        self.done = False\n",
    "\n",
    "    def step(self, action):\n",
    "        # Execute the action on the API and get the response\n",
    "        mutation_methods = {}\n",
    "        mutation_methods[int] = self.mutation_methods[0][action[0]]\n",
    "        mutation_methods[float] = self.mutation_methods[1][action[1]]\n",
    "        mutation_methods[bool] = self.mutation_methods[2][action[2]]\n",
    "        mutation_methods[bytes] = self.mutation_methods[3][action[3]]\n",
    "        mutation_methods[str] = self.mutation_methods[4][action[4]]\n",
    "        \n",
    "        resp = \"\"\n",
    "        count = -1\n",
    "        while type(resp) is str:\n",
    "            count = count + 1\n",
    "            if self.function['method'] == 'POST':\n",
    "                if count == 5:\n",
    "                    print(\"stuck here\")\n",
    "                    self.function = fill_values(self.function, False, mutation_methods, True)\n",
    "                    count = 0\n",
    "                else:\n",
    "                    self.function = fill_values(self.function, True, mutation_methods, True)\n",
    "            else:\n",
    "                if count == 5:\n",
    "                    self.function = fill_values(self.function, False, mutation_methods, False)\n",
    "                    count = 0\n",
    "                else:\n",
    "                    self.function = fill_values(self.function, True, mutation_methods, False)\n",
    "                \n",
    "            \n",
    "            resp = self._execute_action(self.function)\n",
    "\n",
    "        self.response = resp\n",
    "        requests_log.append({\"status_code\": self.response.status_code, \"message\": self.response.content})\n",
    "\n",
    "        self._update_environment_state()\n",
    "\n",
    "        # Calculate the reward based on the response\n",
    "        reward = self._calculate_reward()\n",
    "\n",
    "        # Return the new state, reward, and episode completion status\n",
    "        return self.state, reward, self.done\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = 1\n",
    "        self.done = False\n",
    "        return self.state\n",
    "\n",
    "    def _execute_action(self, function):\n",
    "        parameters = {}\n",
    "        headers = {'Content-type': function['content-type'], 'Accept': '*/*'}\n",
    "        headers = {'Private-Token': 'glpat-6CnAgwr1hGo9jgvkTdMN'}\n",
    "        path: str = copy.deepcopy(function['path'])\n",
    "        if len(function['input_parameters']) > 0:\n",
    "            for item in function['input_parameters']:\n",
    "                if item['name'] in path:\n",
    "                    path = path.replace('{' + item['name'] + '}', str(item['sample']))\n",
    "                else:\n",
    "                    parameters[item['name']] = str(item['sample'])\n",
    "            \n",
    "        print(\"Sending request\")\n",
    "        \n",
    "        try:\n",
    "            if function['method'] == 'GET':\n",
    "                if len(parameters) > 0:\n",
    "                    return requests.get(self.base_url + path, params=parameters, headers=headers, timeout=40)\n",
    "                else:\n",
    "                    return requests.get(self.base_url + path, headers=headers, timeout=40)\n",
    "            \n",
    "            elif function['method'] == 'PUT':\n",
    "                if len(parameters) > 0:\n",
    "                    return requests.put(self.base_url + path, json=function['input_body']['sample'], headers=headers, params=parameters, timeout=40)\n",
    "                else:\n",
    "                    return requests.put(self.base_url + path, json=function['input_body']['sample'], headers=headers, timeout=40)\n",
    "\n",
    "            elif function['method'] == 'DELETE':\n",
    "                if len(parameters) > 0:\n",
    "                    return requests.delete(self.base_url + path, json=function['input_body']['sample'], headers=headers, params=parameters, timeout=40)\n",
    "                else:\n",
    "                    return requests.delete(self.base_url + path, json=function['input_body']['sample'], headers=headers, timeout=40)\n",
    "            \n",
    "            elif function['method'] == 'POST':\n",
    "                if function['content-type'] == \"multipart/form-data\":\n",
    "                    files = {'file': function['input_body']['sample'].pop('file')}\n",
    "                    if len(parameters) > 0:\n",
    "                        return requests.post(self.base_url + path, json=function['input_body']['sample'], files=files, params=parameters,timeout=40)\n",
    "                    else:\n",
    "                        return requests.post(self.base_url + path, json=function['input_body']['sample'], files=files, timeout=40)\n",
    "                else:\n",
    "                    if len(parameters) > 0:\n",
    "                        return requests.post(self.base_url + path, json=function['input_body']['sample'], headers=headers, params=parameters,timeout=40)\n",
    "                    else:\n",
    "                        return requests.post(self.base_url + path, json=function['input_body']['sample'], headers=headers, timeout=40)\n",
    "        except:\n",
    "            return \"error\"\n",
    "\n",
    "    def _calculate_reward(self):\n",
    "        # Implement the logic to calculate the reward based on the API response\n",
    "        # You can define a reward function that suits your testing objective\n",
    "        # Return the reward value\n",
    "        if int(self.response.status_code) in range(100, 200):\n",
    "            return 0\n",
    "        elif int(self.response.status_code) in range(200, 300):\n",
    "            return 5\n",
    "        elif int(self.response.status_code) in range(300, 400):\n",
    "            return 5\n",
    "        elif int(self.response.status_code) in range(400, 500):\n",
    "            return -20\n",
    "        elif int(self.response.status_code) >= 500:\n",
    "            return 10\n",
    "        \n",
    "        return 0\n",
    "\n",
    "\n",
    "    def _update_environment_state(self):\n",
    "        # Implement any necessary state updates based on the API response\n",
    "        # For example, update the state with new information after each request\n",
    "        # Change the state\n",
    "        if int(self.response.status_code) in range(100, 200):\n",
    "            self.state = 0\n",
    "        elif int(self.response.status_code) in range(200, 300):\n",
    "            self.state = 1\n",
    "        elif int(self.response.status_code) in range(300, 400):\n",
    "            self.state = 2\n",
    "        elif int(self.response.status_code) in range(400, 500):\n",
    "            self.state = 3\n",
    "        elif int(self.response.status_code) >= 500:\n",
    "            self.state = 4\n",
    "            self.done = True\n",
    "            requests_log.append({\"status_code\": self.response.status_code, \"message\": self.response.content})\n",
    "\n",
    "    def _change_environment_function(self, function):\n",
    "        # Changes the function under test\n",
    "        self.function = function\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        # Implement the logic to visualize the environment if needed\n",
    "        if mode == 'human':\n",
    "            # Print the current state or any relevant information for human visualization\n",
    "            print(\"Current state:\", self.state)\n",
    "            print(\"Last response status code:\", self.response.status_code)\n",
    "            # Print any other relevant information about the environment\n",
    "\n",
    "        elif mode == 'machine':\n",
    "            # Return the current state or any relevant information for machine visualization\n",
    "            # You can return it as a dictionary or in any other appropriate format\n",
    "            return {'current_state': self.state, 'last_response_status': self.response.status_code}\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid render mode. Supported modes are 'human' and 'machine'.\")\n",
    "\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent:\n",
    "    def __init__(self, env: APIFuzzyTestingEnvironment, mutation_methods, max_steps_per_episode, learning_rate=0.1, discount_factor=0.9, exploration_rate=0.1, min_exploration_rate=0.1, max_exploration_rate=1, exploration_decay_rate=0.01):\n",
    "        self.env = env\n",
    "        self.int_q_table = np.zeros([env.observation_space.n, len(mutation_methods[0])])\n",
    "        self.float_q_table = np.zeros([env.observation_space.n, len(mutation_methods[1])])\n",
    "        self.bool_q_table = np.zeros([env.observation_space.n, len(mutation_methods[2])])\n",
    "        self.byte_q_table = np.zeros([env.observation_space.n, len(mutation_methods[3])])\n",
    "        self.string_q_table = np.zeros([env.observation_space.n, len(mutation_methods[4])])\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.exploration_rate = exploration_rate\n",
    "        self.min_exploration_rate = min_exploration_rate\n",
    "        self.max_exploration_rate = max_exploration_rate\n",
    "        self.exploration_decay_rate = exploration_decay_rate\n",
    "        self.max_steps_per_episode = max_steps_per_episode\n",
    "        self.episode_rewards = []  # To store the rewards obtained in each episode\n",
    "        self.rewards_all_episodes=[]\n",
    "        self.mutation_methods = mutation_methods\n",
    "        self.mutation_counts = {i: {method: 0 for method in mutation_methods[i]} for i in range(env.observation_space.n)}\n",
    "        self.mutation_rewards = {i: {method: [] for method in mutation_methods[i]} for i in range(env.observation_space.n)}\n",
    "        self.state_visits = np.zeros(env.observation_space.n)\n",
    "        self.q_value_convergence = {}\n",
    "        self.num_episodes = 30\n",
    "\n",
    "    def choose_action(self, state, int_q_table, float_q_table, bool_q_table, byte_q_table, string_q_table):\n",
    "        # Epsilon-greedy exploration policy\n",
    "        if random.uniform(0, 1) < self.exploration_rate:\n",
    "            action = self.env.action_space.sample()\n",
    "        else:\n",
    "            action = []\n",
    "            action.append(np.argmax(int_q_table[state,:]))\n",
    "            action.append(np.argmax(float_q_table[state,:]))\n",
    "            action.append(np.argmax(bool_q_table[state,:]))\n",
    "            action.append(np.argmax(byte_q_table[state,:]))\n",
    "            action.append(np.argmax(string_q_table[state,:]))\n",
    "        return action\n",
    "\n",
    "    def update_q_table(self, state, action, reward, new_state, q_table):\n",
    "        q_table[state, action] = q_table[state, action] * (1 - self.learning_rate) + \\\n",
    "            self.learning_rate * (reward + self.discount_factor * np.max(q_table[new_state, :]))\n",
    "\n",
    "    def train(self, num_episodes):\n",
    "        self.q_value_convergence = {\n",
    "            'int': [],\n",
    "            'float': [],\n",
    "            'bool': [],\n",
    "            'byte': [],\n",
    "            'string': []\n",
    "        }\n",
    "\n",
    "        self.num_episodes = num_episodes\n",
    "\n",
    "        for episode in range(num_episodes):\n",
    "            done = False\n",
    "            state = self.env.reset()\n",
    "            rewards_current_episode = 0\n",
    "\n",
    "            print(episode)\n",
    "\n",
    "            for step in range(self.max_steps_per_episode):\n",
    "                action = self.choose_action(state, self.int_q_table, self.float_q_table, self.bool_q_table, self.byte_q_table, self.string_q_table)\n",
    "                new_state, reward, done = self.env.step(action)\n",
    "                self.update_q_table(state, action[0], reward, new_state, self.int_q_table)\n",
    "                self.update_q_table(state, action[1], reward, new_state, self.float_q_table)\n",
    "                self.update_q_table(state, action[2], reward, new_state, self.bool_q_table)\n",
    "                self.update_q_table(state, action[3], reward, new_state, self.byte_q_table)\n",
    "                self.update_q_table(state, action[4], reward, new_state, self.string_q_table)\n",
    "\n",
    "                for i in range(len(self.mutation_counts)):\n",
    "                    chosen_method = self.mutation_methods[i][action[i]]  # Get the chosen mutation method dynamically\n",
    "                    self.mutation_counts[i][chosen_method] += 1\n",
    "                    self.mutation_rewards[i][chosen_method].append(reward)\n",
    "                \n",
    "                state = new_state\n",
    "                rewards_current_episode += reward\n",
    "                self.episode_rewards.append(reward)\n",
    "                self.state_visits[state] += 1\n",
    "\n",
    "                if done is True:\n",
    "                    break\n",
    "\n",
    "            # Exploration rate decay\n",
    "            self.exploration_rate = self.min_exploration_rate + \\\n",
    "                (self.max_exploration_rate - self.min_exploration_rate) * np.exp(-self.exploration_decay_rate*episode)\n",
    "            \n",
    "            self.rewards_all_episodes.append(rewards_current_episode)\n",
    "            \n",
    "            self.q_value_convergence['int'].append(np.copy(self.int_q_table))\n",
    "            self.q_value_convergence['float'].append(np.copy(self.float_q_table))\n",
    "            self.q_value_convergence['bool'].append(np.copy(self.bool_q_table))\n",
    "            self.q_value_convergence['byte'].append(np.copy(self.byte_q_table))\n",
    "            self.q_value_convergence['string'].append(np.copy(self.string_q_table))\n",
    "\n",
    "        # Calculate and print the average reward per hundred episodes\n",
    "        rewards_per_number_episodes = np.split(np.array(self.rewards_all_episodes),num_episodes/num_episodes)\n",
    "        count = num_episodes\n",
    "        print(\"********Average reward per number of episodes********\\n\")\n",
    "        for r in rewards_per_number_episodes:\n",
    "            print(count, \": \", str(sum(r/num_episodes)))\n",
    "            count += num_episodes\n",
    "\n",
    "    def plot_q_value_convergence(self, base_path):\n",
    "        x = np.arange(0, self.num_episodes)\n",
    "        data_types = ['int', 'float', 'bool', 'byte', 'string']\n",
    "        for data_type in data_types:\n",
    "            q_values = np.array(self.q_value_convergence[data_type])\n",
    "            avg_q_values = np.mean(q_values, axis=(1, 2))  # Average over states and actions\n",
    "            plt.plot(x, avg_q_values, label=data_type)\n",
    "\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.ylabel('Average Q-value')\n",
    "        plt.legend()\n",
    "        plt.title('Q-value Convergence')\n",
    "        plt.savefig(base_path + \"q_value_convergence.png\")\n",
    "        plt.close()\n",
    "\n",
    "    def plot_learning_curve(self, num_episodes):\n",
    "        # Calculate the average reward over a fixed number of episodes (e.g., last 100 episodes) and plot the learning curve\n",
    "        window_size = 10\n",
    "        average_rewards = [np.mean(self.episode_rewards[i:i + window_size]) for i in range(len(self.episode_rewards) - window_size + 1)]\n",
    "        plt.plot(range(window_size, num_episodes + 1), average_rewards)\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.ylabel('Average Reward')\n",
    "        plt.title('Learning Curve')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_action_distribution(self, base_path):\n",
    "        data_types = ['int', 'float', 'bool', 'byte', 'string']\n",
    "        for i in range(len(self.mutation_counts)):\n",
    "            mutation_methods = list(self.mutation_counts[i].keys())\n",
    "            method_counts = list(self.mutation_counts[i].values())\n",
    "            \n",
    "            indices = np.arange(len(mutation_methods))\n",
    "            \n",
    "            # Define a list of colors for the columns\n",
    "            colors = plt.cm.viridis(np.linspace(0, 1, len(mutation_methods)))\n",
    "            \n",
    "            # Use the 'colors' list to set different colors for each column\n",
    "            bars = plt.bar(indices, method_counts, color=colors)\n",
    "            \n",
    "            plt.xticks(indices, indices)\n",
    "            plt.xlabel('Mutation Method Index')\n",
    "            plt.ylabel('Action Counts')\n",
    "            plt.title(f'Action Distribution for {data_types[i]}')\n",
    "            \n",
    "            # Create custom legend handles for each mutation method\n",
    "            legend_handles = [mpatches.Patch(color=colors[j], label=mutation_method.__name__) for j, mutation_method in enumerate(mutation_methods)]\n",
    "            \n",
    "            # Move the legend outside the plot\n",
    "            plt.legend(handles=legend_handles, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "            \n",
    "            # Annotate each bar with the exact number on top\n",
    "            for j, count in enumerate(method_counts):\n",
    "                plt.text(j, count + 0.1, str(count), ha='center', va='bottom')\n",
    "            \n",
    "            plt.savefig(base_path + \"q_action_distribution_\" + str(i) + \".png\", bbox_inches='tight')\n",
    "            plt.close()\n",
    "    \n",
    "    def plot_state_visits(self, base_path):\n",
    "        states = list(range(len(self.state_visits)))\n",
    "        visit_counts = list(self.state_visits)\n",
    "        \n",
    "        # Define legend labels for HTTP status code ranges\n",
    "        legend_labels = ['1XX', '2XX', '3XX', '4XX', '5XX']\n",
    "        \n",
    "        # Define colors for each HTTP status code range\n",
    "        colors = ['lightblue', 'green', 'yellow', 'orange', 'red']\n",
    "        \n",
    "        plt.bar(states, visit_counts, color=colors)\n",
    "        plt.xlabel('HTTP Status Code Ranges')\n",
    "        plt.ylabel('Number of Visits')\n",
    "        plt.title('Number of Visits to Each HTTP Status Code Range')\n",
    "        \n",
    "        # Set x-axis ticks and labels to the legend labels\n",
    "        plt.xticks(states, legend_labels)\n",
    "        \n",
    "        # Annotate each bar with the exact number on top\n",
    "        for state, count in zip(states, visit_counts):\n",
    "            plt.text(state, count + 0.1, str(count), ha='center', va='bottom')\n",
    "        \n",
    "        plt.savefig(base_path + \"state_visits.png\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    def test(self):\n",
    "        for episode in range(5):\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "\n",
    "            print(\"*******Episode \", episode+1, \"*******\\n\\n\")\n",
    "            for step in range(self.max_steps_per_episode):        \n",
    "                # Choose action with highest Q-value for current state\n",
    "                self.env.render()\n",
    "                # Take new action\n",
    "                # time.sleep(0.3)\n",
    "                action = []\n",
    "                action.append(np.argmax(self.int_q_table[state,:]))\n",
    "                action.append(np.argmax(self.float_q_table[state,:]))\n",
    "                action.append(np.argmax(self.bool_q_table[state,:]))\n",
    "                action.append(np.argmax(self.byte_q_table[state,:]))\n",
    "                action.append(np.argmax(self.string_q_table[state,:]))\n",
    "                new_state, reward, done = self.env.step(action)\n",
    "\n",
    "                if done:\n",
    "                    env.render()\n",
    "                    if reward == 1:\n",
    "                        # Agent reached the goal and won episode\n",
    "                        print(\"****You reached the goal****\")\n",
    "                        # time.sleep(3)\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"****You lost****\")\n",
    "                    # time.sleep(3)\n",
    "\n",
    "                state = new_state\n",
    "\n",
    "def write_agent_report(base_folder, agent_name, agent: QLearningAgent):\n",
    "    # time.sleep(3)\n",
    "    try:\n",
    "        directory = os.path.dirname(base_folder + \"/\" + agent_name + \"/\")\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        # Decode bytes in requests_log\n",
    "        requests_log_decoded = []\n",
    "        for request in requests_log:\n",
    "            decoded_request = {}\n",
    "            for key, value in request.items():\n",
    "                if isinstance(value, bytes):\n",
    "                    decoded_request[key] = value.decode('utf-8')\n",
    "                else:\n",
    "                    decoded_request[key] = value\n",
    "            requests_log_decoded.append(decoded_request)\n",
    "        \n",
    "        with open(base_folder + \"/\" + agent_name + \"/report.log\", \"w\") as file:\n",
    "            file.write(\"\\n\\n------ List of IDs ------\\n\\n\")\n",
    "            json.dump(ids, file, indent=4)\n",
    "            file.write(\"\\n\\n------ List of Requests ------\\n\\n\")\n",
    "            json.dump(requests_log_decoded, file, indent=4)\n",
    "            file.write(\"\\n\\n------ Q-tables ------\\n\\n\")\n",
    "            file.write(\"   Int table\\n\")\n",
    "            file.write(str(agent.int_q_table))\n",
    "            file.write(\"\\n   Float table\\n\")\n",
    "            file.write(str(agent.float_q_table))\n",
    "            file.write(\"\\n   Bool table\\n\")\n",
    "            file.write(str(agent.bool_q_table))\n",
    "            file.write(\"\\n   String table\\n\")\n",
    "            file.write(str(agent.string_q_table))\n",
    "            file.write(\"\\n   Byte table\\n\")\n",
    "            file.write(str(agent.byte_q_table))\n",
    "            \n",
    "            agent.plot_q_value_convergence(base_folder + \"/\" + agent_name + \"/\")\n",
    "            agent.plot_action_distribution(base_folder + \"/\" + agent_name + \"/\")\n",
    "            agent.plot_state_visits(base_folder + \"/\" + agent_name + \"/\")\n",
    "    except IOError as e:\n",
    "        print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "getApiV4GroupsIdBadgesBadgeId\n",
      "{'content': {'application/json': {'schema': {'properties': {'link_url': {'type': 'string', 'description': 'URL of the badge link'}, 'image_url': {'type': 'string', 'description': 'URL of the badge image'}, 'name': {'type': 'string', 'description': 'Name for the badge'}}}}}}\n",
      "{'link_url': 'string', 'image_url': 'string', 'name': 'string'}\n",
      "putApiV4GroupsIdBadgesBadgeId\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'capitalize'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 113\u001B[0m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;66;03m# if schema is None:\u001B[39;00m\n\u001B[0;32m    109\u001B[0m \u001B[38;5;66;03m#     input_body = {\"schema\": [], \"sample\": None, \"schema_name\": None}\u001B[39;00m\n\u001B[0;32m    111\u001B[0m input_body \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mschema\u001B[39m\u001B[38;5;124m\"\u001B[39m: schema, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msample\u001B[39m\u001B[38;5;124m\"\u001B[39m: copy\u001B[38;5;241m.\u001B[39mdeepcopy(schema), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mschema_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: schema_name}\n\u001B[1;32m--> 113\u001B[0m function \u001B[38;5;241m=\u001B[39m \u001B[43mfill_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\n\u001B[0;32m    114\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpath\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    115\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcontent-type\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_applicaton\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    116\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmethod\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupper\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    117\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput_parameters\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_parameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput_body\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_body\u001B[49m\n\u001B[0;32m    119\u001B[0m \u001B[43m\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;66;03m# Store the information in the functions dictionary\u001B[39;00m\n\u001B[0;32m    122\u001B[0m functions[function_name] \u001B[38;5;241m=\u001B[39m function\n",
      "Cell \u001B[1;32mIn[3], line 134\u001B[0m, in \u001B[0;36mfill_values\u001B[1;34m(function, contains_previous_values, mutation_methods, store_id)\u001B[0m\n\u001B[0;32m    132\u001B[0m     function[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_body\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msample\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m items\n\u001B[0;32m    133\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 134\u001B[0m     function[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_body\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msample\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mfill_body_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput_body\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mschema\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput_body\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msample\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontains_previous_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmutation_methods\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput_body\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mschema_name\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m function\n",
      "Cell \u001B[1;32mIn[3], line 52\u001B[0m, in \u001B[0;36mfill_body_values\u001B[1;34m(schema, old_sample, contains_previous, mutation_methods, schema_name, store_id)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(item[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mstr\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m item[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minteger\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdouble\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfloat\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstring\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mboolean\u001B[39m\u001B[38;5;124m\"\u001B[39m}:\n\u001B[1;32m---> 52\u001B[0m         val \u001B[38;5;241m=\u001B[39m get_mutated_value(\u001B[38;5;28;01mNone\u001B[39;00m, item[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;28;01mNone\u001B[39;00m, Word(\u001B[43mschema_name\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcapitalize\u001B[49m())\u001B[38;5;241m.\u001B[39msingularize())\n\u001B[0;32m     53\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m val \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m                 \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVal is None!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'capitalize'"
     ]
    }
   ],
   "source": [
    "# Read the OpenAPI specification file (assuming it's in YAML format)\n",
    "with open('./Projects/authentiq/openapi.yaml', 'r') as file:\n",
    "    spec = yaml.safe_load(file)\n",
    "\n",
    "# Extract the base connection string (servers -> url)\n",
    "base_url = spec['servers'][0]['url']\n",
    "\n",
    "# Load schemas\n",
    "schemas = {}\n",
    "\n",
    "#ID dicts\n",
    "ids = {}\n",
    "\n",
    "while len(schemas.keys()) != len(spec['components']['schemas'].keys()):\n",
    "    filtered_dict = {obj_name: obj_props for obj_name, obj_props in spec['components']['schemas'].items() if obj_name not in schemas.keys()}\n",
    "    for object_name, object_data in filtered_dict.items():\n",
    "        try:\n",
    "            parameter_schema = create_json_body(object_data, schemas)\n",
    "            schemas[object_name] = parameter_schema\n",
    "            if 'id' in parameter_schema:\n",
    "                ids[object_name] = []\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "if 'requestBodies' in spec['components']:\n",
    "    for object_name, object_data in spec['components']['requestBodies'].items():\n",
    "        parameter_schema = create_json_body(object_data, schemas)\n",
    "        schemas[object_name] = parameter_schema\n",
    "        if 'id' in parameter_schema:\n",
    "            ids[object_name] = []\n",
    "\n",
    "# Extract the functions, input schemas, and output schemas\n",
    "functions = {}\n",
    "for path, path_item in spec['paths'].items():\n",
    "    for method, operation in path_item.items():\n",
    "        function_name = operation.get('operationId')\n",
    "        request_body = operation.get('requestBody')\n",
    "        request_parameters = operation.get('parameters')\n",
    "        input_schema = None\n",
    "        parameter_name = None\n",
    "        parameter_in  = None\n",
    "        parameter_schema = None\n",
    "        parameter_type = None\n",
    "        schema = None\n",
    "        schema_name = None\n",
    "\n",
    "        function_parameters: list = []\n",
    "\n",
    "        # Extract parameters\n",
    "        if request_parameters != None:\n",
    "            for parameters in request_parameters:\n",
    "                if request_parameters != None:\n",
    "                    parameter_name = parameters['name']\n",
    "                    parameter_in = parameters['in']\n",
    "                    parameter_schema = parameters['schema']['type']\n",
    "\n",
    "                    if parameter_schema == 'array':\n",
    "                        parameter_schema = [parameters['schema']['items']['type']]\n",
    "\n",
    "                function_parameters.append({\n",
    "                    \"name\": parameter_name,\n",
    "                    \"in\": parameter_in,\n",
    "                    \"schema\": parameter_schema,\n",
    "                    \"sample\": copy.deepcopy(parameter_schema)\n",
    "                })\n",
    "\n",
    "        input_applicaton = 'application/json'\n",
    "\n",
    "        # Extract input schema\n",
    "        if(request_body != None and 'content' in request_body):\n",
    "            print(request_body)\n",
    "            input_schema = request_body['content']\n",
    "            if 'application/json' in input_schema:\n",
    "                input_applicaton = 'application/json'\n",
    "                input_schema = input_schema['application/json']['schema']\n",
    "            elif 'application/octet-stream' in input_schema:\n",
    "                input_applicaton = 'application/octet-stream'\n",
    "                input_schema = input_schema['application/octet-stream']['schema']\n",
    "            elif 'application/x-www-form-urlencoded' in input_schema:\n",
    "                input_applicaton = 'application/x-www-form-urlencoded'\n",
    "                input_schema = input_schema['application/x-www-form-urlencoded']['schema']\n",
    "            elif 'multipart/form-data' in input_schema:\n",
    "                input_applicaton = 'multipart/form-data'\n",
    "                input_schema = input_schema['multipart/form-data']['schema']\n",
    "\n",
    "            if 'type' in input_schema:\n",
    "                if input_schema['type'] == 'array':\n",
    "                    schema = \"array\"\n",
    "                    schema_type = input_schema['items']\n",
    "                    if 'type' in schema_type:\n",
    "                        schema_type = input_schema['items']['type']\n",
    "                    elif '$ref' in schema_type:\n",
    "                        schema_name = input_schema['items']['$ref'].split('/')[-1]\n",
    "                        schema = schemas.get(schema_name)\n",
    "                else:\n",
    "                    schema = input_schema['type']\n",
    "            \n",
    "            if '$ref' in input_schema:\n",
    "                schema_name = input_schema['$ref'].split('/')[-1]\n",
    "                schema = schemas.get(schema_name)\n",
    "\n",
    "            if 'properties' in input_schema:\n",
    "                schema = create_json_body(input_schema, {})\n",
    "\n",
    "        print(schema)\n",
    "        print(function_name)\n",
    "        \n",
    "        # if schema is None:\n",
    "        #     input_body = {\"schema\": [], \"sample\": None, \"schema_name\": None}\n",
    "        \n",
    "        input_body = {\"schema\": schema, \"sample\": copy.deepcopy(schema), \"schema_name\": schema_name}\n",
    "\n",
    "        function = fill_values({\n",
    "            'path': path,\n",
    "            'content-type': input_applicaton,\n",
    "            'method': method.upper(),\n",
    "            'input_parameters': function_parameters,\n",
    "            'input_body': input_body\n",
    "        }, False, None, False)\n",
    "\n",
    "        # Store the information in the functions dictionary\n",
    "        functions[function_name] = function\n",
    "\n",
    "# Print the base URL and functions dictionary\n",
    "print(\"Base URL:\", base_url)\n",
    "print(\"Methods: \", functions.keys())\n",
    "print(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['getApiV4GroupsIdBadgesBadgeId', 'putApiV4GroupsIdBadgesBadgeId', 'deleteApiV4GroupsIdBadgesBadgeId', 'getApiV4GroupsIdBadges', 'postApiV4GroupsIdBadges', 'getApiV4GroupsIdBadgesRender', 'deleteApiV4GroupsIdAccessRequestsUserId', 'putApiV4GroupsIdAccessRequestsUserIdApprove', 'getApiV4GroupsIdAccessRequests', 'postApiV4GroupsIdAccessRequests', 'deleteApiV4ProjectsIdRepositoryMergedBranches', 'getApiV4ProjectsIdRepositoryBranchesBranch', 'deleteApiV4ProjectsIdRepositoryBranchesBranch', 'headApiV4ProjectsIdRepositoryBranchesBranch', 'getApiV4ProjectsIdRepositoryBranches', 'postApiV4ProjectsIdRepositoryBranches', 'putApiV4ProjectsIdRepositoryBranchesBranchUnprotect', 'putApiV4ProjectsIdRepositoryBranchesBranchProtect', 'getApiV4ProjectsIdBadgesBadgeId', 'putApiV4ProjectsIdBadgesBadgeId', 'deleteApiV4ProjectsIdBadgesBadgeId', 'getApiV4ProjectsIdBadges', 'postApiV4ProjectsIdBadges', 'getApiV4ProjectsIdBadgesRender', 'deleteApiV4ProjectsIdAccessRequestsUserId', 'putApiV4ProjectsIdAccessRequestsUserIdApprove', 'getApiV4ProjectsIdAccessRequests', 'postApiV4ProjectsIdAccessRequests', 'putApiV4ProjectsIdAlertManagementAlertsAlertIidMetricImagesMetricImageId', 'deleteApiV4ProjectsIdAlertManagementAlertsAlertIidMetricImagesMetricImageId', 'getApiV4ProjectsIdAlertManagementAlertsAlertIidMetricImages', 'postApiV4ProjectsIdAlertManagementAlertsAlertIidMetricImages', 'postApiV4ProjectsIdAlertManagementAlertsAlertIidMetricImagesAuthorize', 'getApiV4AdminBatchedBackgroundMigrationsId', 'getApiV4AdminBatchedBackgroundMigrations', 'putApiV4AdminBatchedBackgroundMigrationsIdResume', 'putApiV4AdminBatchedBackgroundMigrationsIdPause', 'getApiV4AdminCiVariablesKey', 'putApiV4AdminCiVariablesKey', 'deleteApiV4AdminCiVariablesKey', 'getApiV4AdminCiVariables', 'postApiV4AdminCiVariables', 'getApiV4AdminDatabasesDatabaseNameDictionaryTablesTableName', 'getApiV4AdminClustersClusterId', 'putApiV4AdminClustersClusterId', 'deleteApiV4AdminClustersClusterId', 'postApiV4AdminClustersAdd', 'getApiV4AdminClusters', 'postApiV4AdminMigrationsTimestampMark', 'deleteApiV4ApplicationsId', 'getApiV4Applications', 'postApiV4Applications', 'getApiV4Avatar', 'getApiV4BroadcastMessagesId', 'putApiV4BroadcastMessagesId', 'deleteApiV4BroadcastMessagesId', 'getApiV4BroadcastMessages', 'postApiV4BroadcastMessages', 'getApiV4BulkImportsImportIdEntitiesEntityId', 'getApiV4BulkImportsImportIdEntities', 'getApiV4BulkImportsImportId', 'getApiV4BulkImportsEntities', 'getApiV4BulkImports', 'postApiV4BulkImports', 'getApiV4ApplicationAppearance', 'putApiV4ApplicationAppearance', 'getApiV4ApplicationPlanLimits', 'putApiV4ApplicationPlanLimits', 'getApiV4Metadata', 'getApiV4Version'])\n"
     ]
    }
   ],
   "source": [
    "print(functions.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request\n",
      "b'{\"message\":\"404 Group Not Found\"}'\n",
      "404\n",
      "-20\n",
      "[0, 0, 0, 0, 0]\n",
      "NEXT STATE AND REWARD\n",
      "1\n",
      "-20\n",
      "Sending request\n",
      "b'{\"message\":\"404 Group Not Found\"}'\n",
      "404\n",
      "-20\n",
      "[1, 1, 1, 1, 1]\n",
      "NEXT STATE AND REWARD\n",
      "1\n",
      "-20\n",
      "Sending request\n",
      "b'{\"message\":\"404 Group Not Found\"}'\n",
      "404\n",
      "-20\n",
      "[2, 2, 2, 2, 2]\n",
      "NEXT STATE AND REWARD\n",
      "1\n",
      "-20\n",
      "Sending request\n",
      "b'{\"message\":\"404 Group Not Found\"}'\n",
      "404\n",
      "-20\n",
      "[3, 3, 0, 3, 3]\n",
      "NEXT STATE AND REWARD\n",
      "1\n",
      "-20\n",
      "Sending request\n",
      "b'{\"message\":\"404 Group Not Found\"}'\n",
      "404\n",
      "-20\n",
      "[4, 4, 1, 4, 4]\n",
      "NEXT STATE AND REWARD\n",
      "1\n",
      "-20\n",
      "Sending request\n",
      "b'{\"message\":\"404 Group Not Found\"}'\n",
      "404\n",
      "-20\n",
      "[5, 5, 2, 5, 5]\n",
      "NEXT STATE AND REWARD\n",
      "1\n",
      "-20\n",
      "Sending request\n",
      "b'{\"message\":\"404 Group Not Found\"}'\n",
      "404\n",
      "-20\n",
      "[6, 6, 0, 6, 6]\n",
      "NEXT STATE AND REWARD\n",
      "1\n",
      "-20\n",
      "Sending request\n",
      "b'{\"message\":\"404 Group Not Found\"}'\n",
      "404\n",
      "-20\n",
      "[7, 7, 1, 7, 0]\n",
      "NEXT STATE AND REWARD\n",
      "1\n",
      "-20\n",
      "Sending request\n",
      "b'[]'\n",
      "200\n",
      "5\n",
      "[0, 0, 2, 8, 1]\n",
      "NEXT STATE AND REWARD\n",
      "1\n",
      "5\n",
      "Sending request\n",
      "b'{\"message\":\"404 Group Not Found\"}'\n",
      "404\n",
      "-20\n",
      "[0, 0, 2, 8, 1]\n",
      "NEXT STATE AND REWARD\n",
      "1\n",
      "-20\n",
      "Sending request\n",
      "b'{\"message\":\"404 Group Not Found\"}'\n",
      "404\n",
      "-20\n",
      "[1, 1, 2, 9, 2]\n"
     ]
    }
   ],
   "source": [
    "# Initialize mutation methods for different data types\n",
    "int_mutation_methods = [bit_flips, byte_shuffling, bytes_substitution, arithmetic_addition, arithmetic_subtraction, arithmetic_multiplication, arithmetic_division, random_generation, dictionary_fuzzy]\n",
    "float_mutation_methods = [bit_flips, byte_shuffling, bytes_substitution, arithmetic_addition, arithmetic_subtraction, arithmetic_multiplication, arithmetic_division, random_generation]\n",
    "bool_mutation_methods = [bit_flips, byte_shuffling, random_generation]\n",
    "byte_mutation_methods = [bit_flips, byte_shuffling, byte_injection, byte_deletion, bytes_substitution, truncation, arithmetic_addition, arithmetic_subtraction, arithmetic_multiplication, arithmetic_division, random_generation]\n",
    "str_mutation_methods = [bit_flips, byte_shuffling, byte_injection, byte_deletion, bytes_substitution, truncation, random_generation]\n",
    "\n",
    "# Combine all mutation methods into a single list\n",
    "mutation_methods = [int_mutation_methods, float_mutation_methods, bool_mutation_methods, byte_mutation_methods, str_mutation_methods]\n",
    "\n",
    "scenarios = [['getApiV4GroupsIdBadgesBadgeId']]\n",
    "env = None\n",
    "requests_log=[]\n",
    "\n",
    "for scenario_functions in scenarios:\n",
    "    for function in scenario_functions:\n",
    "        requests_log = []\n",
    "        print(\"Starting \" + function)\n",
    "        if env is None:\n",
    "            # Create an instance of the API testing environment\n",
    "            env = APIFuzzyTestingEnvironment(base_url, functions[function], mutation_methods)\n",
    "        else:\n",
    "            env._change_environment_function(functions[function])\n",
    "        \n",
    "        # Create an instance of the Q-Learning agent\n",
    "        agent = QLearningAgent(env,mutation_methods,10,exploration_rate=1)\n",
    "\n",
    "        # Train the agent\n",
    "        agent.train(num_episodes=500)\n",
    "\n",
    "        write_agent_report(\"execution/train/\", function, agent)\n",
    "\n",
    "        requests_log = []\n",
    "\n",
    "        # Test the agent\n",
    "        agent.test()\n",
    "\n",
    "        write_agent_report(\"execution/test/\", function, agent)\n",
    "\n",
    "        print(function + \" ended.\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1758034295.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[7], line 1\u001B[1;36m\u001B[0m\n\u001B[1;33m    falta organizar o dicionario que guardar elementos para passar p op proximo agente\u001B[0m\n\u001B[1;37m          ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "falta organizar o dicionario que guardar elementos para passar p op proximo agente\n",
    "\n",
    "Falta meter metricas no agente\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('FuzzTheREST_Env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dad350b7cd3d73302ca3573125e19e8320c4d01cc9050cd16ab7cf7cf76f761"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
